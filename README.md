ğŸ“Œ README.md â€” ArtVector
(Semantic Retrieval Engine for Cultural Data)

1. Project Overview
ArtVector is a semantic retrieval engine for museum and cultural heritage datasets.
It ingests large metadata exports (e.g., The Metropolitan Museum of Art Open Access CSV),
converts objects into latent embedding space, and enables meaning-based search
without keyword matching.
This system is intended as:
âœ” a research/prototype platform
âœ” an institutional discovery layer
âœ” a foundation for future vector database integrations
âœ” a demonstrator for semantic search over cultural objects

2. System Function
ArtVector performs:
Dataset ingestion
â†’ Extracts usable objects and fields
Representation learning
â†’ Embeds text metadata using SentenceTransformer models
Indexing and batching
â†’ Builds progressive embedding matrix in memory
Semantic evaluation & retrieval
â†’ Converts queries into embedding space
â†’ Computes cosine similarity to items
â†’ Returns top-K meaning neighbors

3. Why This Exists
Museums store millions of objects but:
indexing is literal
subject terms are inconsistent
keywords donâ€™t capture artistic meaning
cross-collection similarity is invisible
ArtVector produces latent search:
â€œfloral abstract etchingâ€
â€œmexican surrealist woodcutâ€
â€œfemale portrait lithograph 1950sâ€
â€œbronze ritual vesselâ€
â€¦ return objects that fit meaningfully, not literally.

4. Architecture
frontend/  (Streamlit UI)
backend/   (FastAPI embedding + retrieval engine)
docker     (Isolation + reproducibility)
Components:
4.1 Backend (FastAPI)
Dataset loader
Latent embedding engine
Cosine similarity / ANN search
Progressive batching system
4.2 Embedding engine
SentenceTransformer: all-MiniLM-L6-v2
Normalized 384-dim vector output
4.3 In-memory vector store
Stores:
OBJECTS                â†’ list of dicts
EMBEDDINGS             â†’ torch tensor [N, D]
EMBEDDED_INDICES       â†’ mapping embeddings â†’ objects
UNEMBEDDED_INDICES     â†’ work queue
4.4 Frontend
Dataset upload
Embedding progress polling
Semantic text search UI
Image preview + metadata readout

5. Execution Flow
Upload
CSV â†’ parse rows â†’ build object list â†’ reset embedding state
Indexing
Loop:
take N pending objects â†’
build text â†’
embedding â†’
normalize â†’
append to tensor â†’
update index â†’
repeat until done
Search
text query â†’
embed â†’
cosine similarity â†’
return best neighbors

6. Technologies Used
FastAPI â€” backend API framework
Torch â€” cosine similarity + tensor operations
SentenceTransformers â€” semantic encoding
Streamlit â€” UI layer
Docker Compose â€” two-service orchestration

7. Installation
Requirements
Docker Desktop (Mac / Windows / Linux)
Internet (first run downloads SentenceTransformer)
Run
docker compose up --build
Visit UI:
http://localhost:8501

8. Usage
1. Upload a Met-style Open Access CSV
â†’ UI reads dataset â†’ backend extracts objects
2. Start indexing
Embeds objects in progressive batches
UI polls /job_status
Progress bar updates
3. Semantic search
Enter queries like:
surrealist female portrait
religious woodcut print
bronze ritual vessel
abstract lithograph 1950s
Returns meaningfully related objects (not literal matches).

9. API Endpoints (Backend)
/upload_dataset
POST CSV â†’ ingest objects
/process_batch
Run N embeddings â†’ append to tensor
/job_status
Return process state
/search_text?q=...&limit=N
Return semantic neighbors

10. Embedding Model Notes
Model:
sentence-transformers/all-MiniLM-L6-v2
384-dim dense vector
cosine-normalized output
Properties:
good CPU inference speed
robust for metadata short text
meaning separation in cultural terminology
Swappable â€” see section 13.

11. Performance Notes
Handles 300â€“500k objects on a modern MacBook / cloud VM
Embedding cost scales linearly
Fast search via vector normalization and top-k similarity
Future work:
approximate nearest neighbor index
persistent vector store

12. Limitations
This version is in-memory only, meaning:
âŒ embeddings disappear on restart
âŒ not multi-user persistent
âŒ not optimized for ANN querying
These are intentional â€” the app is an engine prototype, not the enterprise artifact.

13. Model Substitution Guide
To change embeddings:
Edit:
backend/embedding.py
Swap:
"sentence-transformers/all-MiniLM-L6-v2"
for:
multi-qa-MiniLM-L6-cos-v1 (ranking optimized)
all-mpnet-base-v2 (higher semantic richness)
CLIP text encoder for multimodal future work

14. Roadmap (Turning Prototype â†’ Product)
Phase 1 â€” Add persistence (pgVector, Qdrant, or Vespa)
Phase 2 â€” Add enrichment UI (taxonomy filling, clustering, similarity sets)
Phase 3 â€” Add authority vocabulary linking (ULAN, AAT, VIAF)
Phase 4 â€” Multimodal support (image embeddings + alignment)
Phase 5 â€” Access control, curator workspace, annotation layer
Phase 6 â€” Packaging for institutional deployment

15. Concept Summary
ArtVector is an indexing engine that transforms cultural metadata into latent space, enabling institutional search and discovery by meaning rather than keywords.
